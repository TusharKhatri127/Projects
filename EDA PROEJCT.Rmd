---
title: "CREDIT RISK ANALYSIS"
author: "Tushar Khatri"
date: "06/09/2022"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Introduction
```
The kernel is taken from Lao Tse under the CC0 public licence (usability 7/10). Data is related to the credit market. Feel free to modify, discuss or improve the code.
```

# Aims of the analysis
```
The aims of the analysis is to search for statistical relationships that could give us some insigths about 
the risk of credit for both lenders and borrowers. Given that the variables and the context of the dataset are
not fully explained, we are not going to take into account external macroeconomic events, which could completely
change the results of the analysis. For instance, different countries could have different loan's requirement, 
or different phases of the economic cycle could end up in a very different scenario. Therefore, the aim of the 
analysis is purely descriptive and should be adapted according to circumstances.
```
# Loading libraries

```{r}
library(haven)
library(dplyr)
library(ggplot2)
library(forcats)
library(tidyverse)
library(gridExtra)
library(tidyverse)
library(ggExtra)

```

### The dataset
```{r}
credit_risk_dataset <- read.csv("C:/Users/TUSHAR/Downloads/Credit card EDA.csv")

```

### Transforming variables to factors
```{r}
credit_risk_dataset$loan_status <- as.factor(credit_risk_dataset$loan_status)
credit_risk_dataset$person_home_ownership <- as.factor(credit_risk_dataset$person_home_ownership)
credit_risk_dataset$loan_intent <- as.factor(credit_risk_dataset$loan_intent)
credit_risk_dataset$loan_grade <- as.factor(credit_risk_dataset$loan_grade)
credit_risk_dataset$cb_person_default_on_file <- as.factor(credit_risk_dataset$cb_person_default_on_file)
glimpse(credit_risk_dataset) # more ordered
#str(credit_risk_dataset)
```
# Data Description

## The dataset is composed by 32581 rows (observations) and 12 columns (variables).

```

person_age:             is the age of the person at the time of the loan.
person_income:          is the yearly income of the person at the time of the loan.
person_home_ownership:  is the type of ownership of the home.
person_emp_length:      is the amount of time in years that person is employed.
loan_intent:            is the aim of the loan.
loan_grade:             is a classification system that involves assigning a quality score to a loan based
                        on a borrower's credit history, quality of the collateral, and the likelihood of 
                        repayment of the principal and interest.
loan_amnt:              is the dimension of the loan taken.
loan_int_rate:          is the interest paid for the loan.
loan_status:            is a dummy variable where 1 is default, 0 is not default.
loan_percent_income:    is the ratio between the loan taken and the annual income.
cb_person_default_on_file: answers whether the person has defaulted before.
cb_person_cred_hist_length: represents the number of years of personal history since the 
                           first loan taken from that person.

```
### The first thing to do is to clean the dataset, looking for missing values (NAs) and for inconsistent data.

```{r}
# To spot missing values
summary(credit_risk_dataset)

```
# Exploratory Data Analysis 

### Obervation from Dataset
```
Here we can notice a few important things as the summary of the variables gives us a first insight of the data:
person_age has a strange result: the max value is 144 which is unlikely to be true.
person_emp_length has 895 NAs
person_emp_length has a max value of 123 which is not possible.
loan_interest_rate has 3116 NAs
according to the data (loan_status), 21.82% (7108/32581) of people have defaulted, value that is quite high.
plot(credit_risk_dataset$person_age, credit_risk_dataset$person_emp_length)
```

```{r}
plot(credit_risk_dataset$person_age, credit_risk_dataset$person_emp_length)
```

### Interpretation
```
Here we can see clearly that there are some issues on data by looking at outliers. It is impossible that two 20 
years old have over 120 years of experience. Therefore we proceed by cleaning our dataset and removing illogical
outliers. We have to adjust data properly before starting the exploratory phase.
```
## Data Cleaning
```{r}
credit_risk <- credit_risk_dataset %>%
    filter(!is.na(person_emp_length)) %>%
    filter(!is.na(loan_int_rate)) %>%
    filter(person_age < 90) %>%
    filter(person_emp_length < 100)

summary(credit_risk)
```

```
Now the dataset seems better.

With the summary command we extrapolate some information about tha characteristics and the distribution of the 
variables that compose our data. For instance, looking at the nature of variables we can divide them in two classes:
numerical and categorical.

We could also divide the variables conceptually. For instance, person_age, person_income, person_home_ownership and
person_emp_length rely on personal characteristics of people, while loan_intent, loan_grade, loan_amnt, loan_int_rate
, loan_status and loan_percent_income rely on their credit activity. The last two variables are of interest only for
secondary purposes.

With this in mind, we can proceed with the exploration of statistical relationships by looking at the most influential
variables.
```


```{r}
plot1 <- ggplot(credit_risk, aes(person_age, person_income, col=person_home_ownership)) +
  geom_point() + ylab("Income") + xlab("Age") + labs(color = "Home ownership: ") +
  theme(legend.position="bottom") 
ggExtra::ggMarginal(plot1, type = "boxplot")

```

### Interpretation of Scatter Plot 1
```
The first graph that we have drawn is merely descriptive of people's characteristics. By looking at it we can notice a few
important things:

The distribution of the Age is right-skewed. This means that most of the values lie on the right side of the scale. In 
other words, considering the age, the dataset is populated mostly by young people.
The distribution of the income is right-skewed. Similarly to age, most of values are in the right side of the graph, which
in this case indicates that the distribution of income is not balanced and shows economic inequality.
People that has a mortage seems to have an higher income on average, with respect to people that pays a rent.
```


### Familiarize with the dataset
```
First of all, we start observing statistical relationships between numerical variables. We can do this using traditional
scatterplots and boxplots. To understand the personal characteristics of people and then their credit activity, it seems
reasonable to compare the person age and income, the loan amount and the interest rate, the person income with the loan
amount and finally, the person age and the interest rate. We could also add an additional dimension (with colours) to have
a clearer overview.
```


```{r}
plot2 <- ggplot(credit_risk, aes(loan_amnt, loan_int_rate, col=loan_intent)) +
  geom_point() + ylab("Interest rate") + xlab("Loan Amount") + labs(color = "Loan Intent: ") +
  theme(legend.position="bottom") 
ggExtra::ggMarginal(plot2, type = "boxplot")
```

### Interpretation
```
This second graph represents the relationship between the loan amount taken by people and the interest rate applied.
Here, we can see that there is not a clear correlation between the two variables, thus we can say that they do not 
depend from each other. Moreover, it seems that the loan intent is distributed equally in the sample, which means that
the intent does not influence at all interest rates or the loan amount. In this case distributions are normal Gaussian
with a slight skewness.
```
```{r}
plot3 <- ggplot(credit_risk, aes(loan_amnt, person_income, col=loan_grade)) +
  geom_point() + ylab("Income") + labs(color = "Loan Grade: ") + theme(legend.position="bottom") +
  scale_color_manual(values=c("#66cc99", "#70F000", "#D0FF00", "#F3FF0F", "#FFDB4D", "#FFA64D", "#FF4D4D"))
ggExtra::ggMarginal(plot3, type = "boxplot")
```


### Interpretation
```
Also in this case there is not a clear relationship between income and the loan amount. By adding different colors for
the loan grades we notice a small tendence for people with low income and with a high loan, to have a lower grade. 
However, the statistical relationship is not strong.
```
```{r}
plot4 <- ggplot(credit_risk, aes(person_age, loan_int_rate, col=loan_grade)) +
  geom_point() + ylab("Interest rate") + xlab("Age") +  labs(color = "Loan Grade: ") +
theme(legend.position="bottom") + scale_color_manual(values=c("#66cc99", "#70F000", "#D0FF00", "#F3FF0F", "#FFDB4D", "#FFA64D", "#FF4D4D"))
ggExtra::ggMarginal(plot4, type = "boxplot")
```

### Interpretation
```
This graph is more interesting: it shows the relationship between the age, the interest rate and the loan grade. Here we can clearly see that the loan grade depends on the interest rate which divide the graph in multiple sections. Basically it says that the higher the interest rate, the higher is the risk perceived. This could be due to the method of evaluation of the risk grade of people. Furthermore, we notice that people in the eldery age tend to have lower interest rates on average with respect to younger people.
```

### Variable of interest
``` 
Our variable of interest is the likekihood of default given certain characteristics, therefore we look at the loan_status variable.
```

```{r}
plot5 <- ggplot(credit_risk, aes(loan_percent_income, loan_int_rate, col= factor(loan_status, labels = c("Not default", "Default")))) +
  geom_point() + ylab("Interest rate") + xlab("Loan percent income") + labs(color = "Loan Status: ") + 
  theme(legend.position="bottom") + scale_color_manual(values=c("#66cc99", "#ff3366"))
ggExtra::ggMarginal(plot5, type = "boxplot")


```
### Interpretation

```Here we consider again the level of interest rates, in relation to the ratio between the loan amount and income. The shape of the dots suggests that there isn't a clear relationship between these two varibles, which means that interest rates does not depend at all on the loan percent income. However, the more we approach to an higher ratio, the lower the interest rates become.

Then, if we take into account people that have defaulted in red and people that have not defaulted in green, we can clearly see a rectangular shape with threshold levels towards 12% for interest rates, and 0.3 for the loan percent income variable. This area could be considered less risky for both lenders and borrowers. This seems to be reasonable as higher interest rates and an higher income/loan ratio means that people are less likely to repay their debt.```

```{r}
ggplot(credit_risk, aes(x = factor(loan_status), fill = factor(person_home_ownership))) +
  geom_bar(position = "fill") +
  ylab("Home ownership %") + xlab("Default") + labs(fill = "Type of ownership:") +
  theme(legend.position="top", plot.background = element_rect(colour = "black", size = 1)) + 
  guides(fill = guide_legend(reverse=TRUE)) +
  coord_flip()
```


### Interpretation
```
This graph shows the absolute frequencies of the type of home ownership with respect to people that has defaulted. It is possible to notice that tipically who pays a rent is more likely to default considering all the orher classes.
```
```{r}
ggplot(credit_risk, aes(x = factor(loan_status), fill = factor(loan_intent))) +
  geom_bar(position = "fill") +
  ylab("Loan Intent") + xlab("Credit Default") + labs(fill = "Loan intent:") +
  theme(legend.position="top", plot.background = element_rect(colour = "black", size = 1)) + 
  guides(fill = guide_legend(reverse=TRUE)) +
  coord_flip()
```


### Interpretation
```
Here we compare people that has and has not defaulted, to the purpose of the requested loan. As we have noted before, the loan intent variable is well distributed, however when the loan is dedicated to debts consolidation and for medical purposes, it seems more likely to lead to a default of the debt.

```

```{r}
ggplot(credit_risk, aes(x = factor(loan_status), fill = factor(loan_grade))) +
  geom_bar(position = "fill") + scale_fill_manual(values=c("#66cc99", "#70F000", "#D0FF00", "#F3FF0F", "#FFDB4D", "#FFA64D", "#FF4D4D")) +
  ylab("Loan Grade") + xlab("Credit Default") + labs(fill = "Loan grade:") +
  theme(legend.position="top", plot.background = element_rect(colour = "black", size = 1)) + 
  guides(fill = guide_legend(reverse=TRUE)) +
  coord_flip()

```

### Interpretation
```
Using again the color palette for the risk grade, it is possible to notice that this variable has some predictive power for defaults, thus, it seems to be selected appropriately from the data keeper. According to the data, when the risk grade is higher, it is less likely to have a default. The contrary applies for lower grades.
```

```{r}
g1 <- ggplot(credit_risk, aes(x = factor(loan_status), y = loan_int_rate)) + 
  geom_boxplot(fill = "orange", alpha = 0.2) +
  ylab("Interest rate") + xlab("Credit Default") +
  coord_flip() 

g2 <- ggplot(credit_risk, aes(x = factor(loan_status), y = person_income)) + 
  geom_boxplot(fill = "orange", alpha = 0.2) +
  ylab("Income") + xlab("Credit Default") +
  coord_flip() 

g3 <- ggplot(credit_risk, aes(x = factor(loan_status), y = loan_amnt)) + 
  geom_boxplot(fill = "orange", alpha = 0.2) +
  ylab("Loan Amount") + xlab("Credit Default") +
  coord_flip() 


grid.arrange(g1, g2, g3, ncol = 1, nrow = 3, top = "Default vs Interest rate, Income and Loan amount")
```


### Interpretation
```
Finally we compare the risk of default with three continous variables: the interest rates, the yearly income, and the loan amount. This graph is interesting because it shows clearly that higher interest rates, a lower income and higher credit increase the possibility to have a default.
```


# Inferential statistics
```We use information derived from the descriptive statistics to raise the right questions about our dataset, searching for the causal relationship between the regressands and regressors of our interest. Then we use inferential statistics to search confirmation about our hypothesis and to find the best model that fits with the data through statistical relevance
```


``` Because of the fact that we are looking for a binary dependent variable (loan_status), we will use the logit model for statistical predictions. As independent variables, we initially use all the other columns.

```

# Fitting Logistic Regression to Predict the probability of Default

```{r}

library(ISLR)

logit <- glm(loan_status ~ ., data = credit_risk, family = binomial(link = 'logit'))
summary(logit)
```

### Interpretation
As expected, cb_person_default_on_file and cb_person_cred_hist_length are not statistically meaningful, thus, they should
be removed from the model. We are going to exclude also the variable loan_percent_income to avoid any kind of multicollinearity. 
This is because this measure is only the ratio between income and loan amount, therefore it could create redundance on calculation.


```{r}
logit <- glm(loan_status ~ person_age + person_income + person_emp_length +
            loan_amnt + loan_int_rate + person_home_ownership + loan_intent +
            loan_grade, data = credit_risk, family = binomial)
summary(logit)
```

```
Now we receive a warning message: “glm.fit: fitted probabilities numerically 0 or 1 occurred”. After some research, I discovered that the problem lies on extreme values on one variable, that causes to the predicted probabilities to be indistinguishable from 0 or 1, leading to calculation's problems. We could overcome to this issue by deleting outliers from person_income and running the algorithm again.

```


```{r}
credit_risk <- credit_risk %>%
  filter(person_income < 800000)

logit <- glm(loan_status ~ person_age + person_income + person_emp_length +
            loan_amnt + loan_int_rate + person_home_ownership + loan_intent +
            loan_grade, data = credit_risk, family = binomial)
summary(logit)
```

### Interpretation 

```Deviance residuals look good, even though values are not completely centered on zero and are not symmetrical. The estimates are the parameters of our interest while the Pr(>|z|) column shows the two-tailed p-values testing the null hypothesis that the coefficient is equal to zero. In other words, it shows the significance of the effects for each independent variable. In our model it seems that most of the variable are statistically significant, however, to confirm this hypotesis we proceed by using the anova test, looking at the table of deviance

The difference between the null deviance and the residual deviance shows how our model is doing against the null model, that is a model with only the intercept. The anova test says that adding these variables improves the model significantly, indeed, low p-values means that variables explain a large portion of variability.```



## Interpreting resutls
```
Now we can analyze the fitting and interpret what the model is telling us. As we have seen, the model suggests that most of p-values show statistical relevance on results, apart for the category HOMEIMPROVEMENT of the loan intent and the loan grade B, which are not significative.

The Estimate column represents the coefficients in log-odds form. This means that when we increase the age by one unit, we could expect a change in the log-odds about -0.005981. We could also use these information looking at the sign of each estimate, to understend whether the effect of the predictor is positive or negative.
```

```{r}
cbind(Estimate=round(coef(logit),5),
 OR=round(exp(coef(logit)),5))
```

```Based on the output that we get, when for example the interest rate parameter increases by one unit (keeping all other predictors constant), the odds of y = 1 (default) are 1.0644 higher, or, put differently, they increase about 6.44%. The same logic applies for all other variables, so for example increasing the employment length by one unit lead to a decrease in the odds of defaulting of 0.9837.

An element to be taken into consideration in our analysis is the loan_grade variable. Indeed, here we can notice that as long as we approach to lower grades, the odds of default increase enormously. As we have said before, categorical variables should be interpreted with respect to the base category, so in this case by comparing other levels with the grade A. This variable seems to be very influential and that, of course, depends on the method of evaluation. It could be interesting to look at how they are classified, but that's for another research. For now, we could just say that the graduation is appropriate and is helpful to identify possible default risks for borrowers and lenders.```

# Confusion Matrix 

## Predicted probabilities
```
When developing models for prediction, the most critical metric is regarding how well the model does in predicting the target variable on out-of-sample observations. For that purpose we can compare the predicted target variable versus the observed values through the confusion matrix.```
```
## Precision of Model Fitted using Confusion Matrix

```{r}
predicted <- predict(logit, type = "response")
table(credit_risk$loan_status, predicted > 0.5)
table(credit_risk$loan_status, predicted > 0.5) %>% prop.table()

Confusion_matrix = as.matrix(table(credit_risk$loan_status, predicted > 0.5))
Sensitivity_ =Confusion_matrix[1,1]/(Confusion_matrix[1,1]+Confusion_matrix[2,1])

Specificity_ = Confusion_matrix[2,2]/(Confusion_matrix[1,2]+Confusion_matrix[2,2])
```
# Calculating Speficity and Selectivuty using Confusion matrix
```{r}
Sensitivity_
Specificity_

```


## Conclusions
```
In our analysis we tried to use statistical tools such as the logistic regression to see if it is possible to predict the possibility of default for customers. First of all we have cleaned and organized our dataset by removing inconsistent values. Then, we proceeded by exploring relationships between most important variables. In this way, we discovered that most of the people in the sample is young and that the distribution of income tend to be inequal. There are not clear relationships between most of the variables, however, we found that the loan grade is strictly connected to the interest rate, so this lead us thinking that this variable depends on the method of evaluation. Nevertheless, it has a good explanatory power, therefore we leaved it in our model. By looking at descriptive statistics we also found that there is a specific area that is less risky for both borrowers and lenders and that area ranges below the 12% thresold for interest rates and below 0.3 for the income to loan ratio. Then, we have build a model which could be able to predict with an high rate, the probabilty of default of people. We have seen that the most influential variables are the interest rates, and the categorical variable of the loan grade. This reflects what we found in the exploratory phase. Also the other variables are influential and most of them are statistically significant. In conclusion, by applying the model, we are able to predict correctly about 85.3% of the cases. This is not bad, considering that the inital rate of default was 21.82%. Therefore, the model could be useful to help save money for both borrowers and lenders, making the credit market more efficient.

```


# Insights of above analysis done
```
1) Analyzed statistical relationships on data with 32581 rows and 12 variables to gain insights into credit risk
2) Carried out Exploratory Data Analysis of Credit Risk data using ggplot2, tidyverse, and dplyr packages
3) Fitted a Binary Classification model using Logistic Regression to predict the probability of client default
4) Diagnosed the precision and accuracy of the Logistic Regression model using sensitivity and specificity

```

